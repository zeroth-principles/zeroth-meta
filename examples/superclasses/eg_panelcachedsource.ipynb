{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we will explore how a CachedSource class works. Specifically, we will take the example of a PanelCachedSource, which outputs a DataFrame which has both time-series and cross-sectional dimensions. Focus on how the class automatically caches data generated during previous calls to the instance of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by importing all the necessay libraries. You may have to change the system path here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\raman\\\\zeroth\\\\zeroth-meta\\\\\")\n",
    "\n",
    "from zpmeta.superclasses.panelcachedsource import PanelCachedSource\n",
    "from pandas import DataFrame, Series, concat, MultiIndex, date_range\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us create a subclass of PanelCachedSource that generates a dataframe of random numbers. All we have to do is to implement the \"execute\" method of the superclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPanelCachedSource(PanelCachedSource):\n",
    "    '''Subclasses PanelCachedSource to create a dataframe of random numbers.\n",
    "    Accepts a dictionary of parameters, including:\n",
    "    cols: list of column names\n",
    "    '''\n",
    "    def __init__(self, params: dict = None):\n",
    "        super(RandomPanelCachedSource, self).__init__(params)\n",
    "        self.appendable = dict(xs=True, ts=True)\n",
    "    \n",
    "    def execute(self, call_type=None, entities=None, period=None):\n",
    "        period_idx = date_range(period[0], period[1], freq=self.params['freq'])\n",
    "        result = DataFrame(np.random.randn(len(period_idx), len(entities['cols'])), columns=entities['cols'], index=period_idx)\n",
    "        \n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us insantiate it. Notice how we can set the frequency of data generated in the params while instantiating the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN RandomPanelCachedSource {'freq': 'B'}\n",
      "RUN INITIAL:  {'cols': ['A', 'B', 'C']} (datetime.datetime(2019, 1, 12, 0, 0), datetime.datetime(2019, 1, 31, 0, 0))\n",
      "EXEC INITIAL: [{'cols': ['A', 'B', 'C']}] (datetime.datetime(2019, 1, 12, 0, 0), datetime.datetime(2019, 1, 31, 0, 0))\n",
      "DONE RandomPanelCachedSource {'freq': 'B'}\n",
      "                   A         B         C\n",
      "2019-01-14  0.441478  0.929580 -2.042512\n",
      "2019-01-15  0.379893  0.831835 -1.101505\n",
      "2019-01-16 -1.511699 -0.625444  0.470315\n",
      "2019-01-17  0.748549 -3.339419 -0.169446\n",
      "2019-01-18  1.263152 -0.367059  1.319189\n",
      "2019-01-21 -1.045336  0.679184 -1.877273\n",
      "2019-01-22 -2.147359 -0.189573 -1.299528\n",
      "2019-01-23  0.458948 -0.550585 -0.526745\n",
      "2019-01-24  0.412842 -0.891124 -0.232959\n",
      "2019-01-25  1.305914  1.115277  1.229875\n",
      "2019-01-28 -1.496769  0.688425 -2.200632\n",
      "2019-01-29 -1.021893  0.011651  0.365392\n",
      "2019-01-30 -0.554501 -0.880985 -0.947708\n",
      "2019-01-31 -0.745128  0.890632  1.154647\n"
     ]
    }
   ],
   "source": [
    "daily_df_source = RandomPanelCachedSource(dict(freq='B'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once instantiated, the instance of this class behaves like a function. A function that has \"memory\". This is a more sophisticated form of memoization.\n",
    "\n",
    "Let us call this function object to create some initial dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = daily_df_source(entities=dict(cols=['A','B','C']), period=(datetime(2019,1,12), datetime(2019,1,31)))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us give it some incremental columns. Notice how the class automatically recognizes the additional columns given and generates data only for that additional column and appends it to the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN RandomPanelCachedSource {'freq': 'B'}\n",
      "RUN Nth:  {'cols': ['C', 'D']} None\n",
      "INCREMENTAL Items:  None\n",
      "TOTAL Items:  {'cols': ['C', 'D', 'B', 'A']}\n",
      "DECREMENTAL Items:  {}\n",
      "INCREMENTAL Period:  None\n",
      "TOTAL Period:  (datetime.datetime(2019, 1, 12, 0, 0), datetime.datetime(2019, 1, 31, 0, 0))\n",
      "APPENDABLE XS:True TS:True\n",
      "DONE RandomPanelCachedSource {'freq': 'B'}\n",
      "                   A         B         C         D\n",
      "2019-01-14  0.441478  0.929580 -2.042512  0.887791\n",
      "2019-01-15  0.379893  0.831835 -1.101505 -0.678325\n",
      "2019-01-16 -1.511699 -0.625444  0.470315  0.225756\n",
      "2019-01-17  0.748549 -3.339419 -0.169446 -0.199534\n",
      "2019-01-18  1.263152 -0.367059  1.319189 -0.219332\n",
      "2019-01-21 -1.045336  0.679184 -1.877273 -0.914854\n",
      "2019-01-22 -2.147359 -0.189573 -1.299528 -1.099639\n",
      "2019-01-23  0.458948 -0.550585 -0.526745  1.170923\n",
      "2019-01-24  0.412842 -0.891124 -0.232959 -0.175174\n",
      "2019-01-25  1.305914  1.115277  1.229875  2.122222\n",
      "2019-01-28 -1.496769  0.688425 -2.200632  0.215265\n",
      "2019-01-29 -1.021893  0.011651  0.365392 -0.161634\n",
      "2019-01-30 -0.554501 -0.880985 -0.947708  0.247657\n",
      "2019-01-31 -0.745128  0.890632  1.154647 -0.518558\n"
     ]
    }
   ],
   "source": [
    "df_xs_incremental = daily_df_source(entities=dict(cols=['C', 'D']))\n",
    "print(df_xs_incremental)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we give it the same set of columns but additional time period. Now it generates data only for the \"incremental\" period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN RandomPanelCachedSource {'freq': 'B'}\n",
      "RUN Nth:  {'cols': ['A', 'B', 'C', 'D']} (datetime.datetime(2019, 1, 20, 0, 0), datetime.datetime(2019, 2, 5, 0, 0))\n",
      "INCREMENTAL Items:  None\n",
      "TOTAL Items:  {'cols': ['C', 'A', 'B', 'D']}\n",
      "DECREMENTAL Items:  None\n",
      "INCREMENTAL Period:  (datetime.datetime(2019, 1, 31, 0, 0), datetime.datetime(2019, 2, 5, 0, 0))\n",
      "TOTAL Period:  (datetime.datetime(2019, 1, 12, 0, 0), datetime.datetime(2019, 2, 5, 0, 0))\n",
      "APPENDABLE XS:True TS:True\n",
      "EXEC INCREMENTAL TS1: [{'cols': ['C', 'D', 'B', 'A']}] (datetime.datetime(2019, 1, 31, 0, 0), datetime.datetime(2019, 2, 5, 0, 0))\n",
      "DONE RandomPanelCachedSource {'freq': 'B'}\n",
      "                   A         B         C         D\n",
      "2019-01-14  0.441478  0.929580 -2.042512  0.887791\n",
      "2019-01-15  0.379893  0.831835 -1.101505 -0.678325\n",
      "2019-01-16 -1.511699 -0.625444  0.470315  0.225756\n",
      "2019-01-17  0.748549 -3.339419 -0.169446 -0.199534\n",
      "2019-01-18  1.263152 -0.367059  1.319189 -0.219332\n",
      "2019-01-21 -1.045336  0.679184 -1.877273 -0.914854\n",
      "2019-01-22 -2.147359 -0.189573 -1.299528 -1.099639\n",
      "2019-01-23  0.458948 -0.550585 -0.526745  1.170923\n",
      "2019-01-24  0.412842 -0.891124 -0.232959 -0.175174\n",
      "2019-01-25  1.305914  1.115277  1.229875  2.122222\n",
      "2019-01-28 -1.496769  0.688425 -2.200632  0.215265\n",
      "2019-01-29 -1.021893  0.011651  0.365392 -0.161634\n",
      "2019-01-30 -0.554501 -0.880985 -0.947708  0.247657\n",
      "2019-01-31 -0.745128  0.890632  1.154647 -0.518558\n",
      "2019-02-01  0.687170 -1.457448 -0.318606 -0.936680\n",
      "2019-02-04  0.751901 -0.644338  0.054160  2.028722\n",
      "2019-02-05  0.513544 -0.473130 -0.890661 -0.055944\n"
     ]
    }
   ],
   "source": [
    "df_ts_incremental = daily_df_source(entities=dict(cols=['A','B','C','D']), period=(datetime(2019,1,20), datetime(2019,2,5)))\n",
    "print(df_ts_incremental)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us give it an example where we feed it both additional columns and additional period. As we can see, it will generate data first for only the incremental columns for the existing period, and then incremental dates for all the columns. This helps minimze calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN RandomPanelCachedSource {'freq': 'B'}\n",
      "RUN Nth:  {'cols': ['A', 'B', 'C', 'D', 'E']} (datetime.datetime(2019, 1, 20, 0, 0), datetime.datetime(2019, 2, 10, 0, 0))\n",
      "INCREMENTAL Items:  {'cols': ['E']}\n",
      "TOTAL Items:  {'cols': ['C', 'A', 'B', 'E', 'D']}\n",
      "DECREMENTAL Items:  None\n",
      "INCREMENTAL Period:  (datetime.datetime(2019, 2, 5, 0, 0), datetime.datetime(2019, 2, 10, 0, 0))\n",
      "TOTAL Period:  (datetime.datetime(2019, 1, 12, 0, 0), datetime.datetime(2019, 2, 10, 0, 0))\n",
      "APPENDABLE XS:True TS:True\n",
      "EXEC INCREMENTAL XS1: [{'cols': ['E']}] (datetime.datetime(2019, 1, 12, 0, 0), datetime.datetime(2019, 2, 5, 0, 0))\n",
      "EXEC INCREMENTAL TS1: [{'cols': ['C', 'A', 'B', 'E', 'D']}] (datetime.datetime(2019, 2, 5, 0, 0), datetime.datetime(2019, 2, 10, 0, 0))\n",
      "DONE RandomPanelCachedSource {'freq': 'B'}\n",
      "                   A         B         C         D         E\n",
      "2019-01-14  0.441478  0.929580 -2.042512  0.887791 -0.196169\n",
      "2019-01-15  0.379893  0.831835 -1.101505 -0.678325 -0.095286\n",
      "2019-01-16 -1.511699 -0.625444  0.470315  0.225756  0.692983\n",
      "2019-01-17  0.748549 -3.339419 -0.169446 -0.199534  0.107910\n",
      "2019-01-18  1.263152 -0.367059  1.319189 -0.219332  2.973147\n",
      "2019-01-21 -1.045336  0.679184 -1.877273 -0.914854  0.154969\n",
      "2019-01-22 -2.147359 -0.189573 -1.299528 -1.099639 -0.098561\n",
      "2019-01-23  0.458948 -0.550585 -0.526745  1.170923  0.276445\n",
      "2019-01-24  0.412842 -0.891124 -0.232959 -0.175174 -0.410377\n",
      "2019-01-25  1.305914  1.115277  1.229875  2.122222  2.070560\n",
      "2019-01-28 -1.496769  0.688425 -2.200632  0.215265  0.135758\n",
      "2019-01-29 -1.021893  0.011651  0.365392 -0.161634 -0.320859\n",
      "2019-01-30 -0.554501 -0.880985 -0.947708  0.247657 -2.056800\n",
      "2019-01-31 -0.745128  0.890632  1.154647 -0.518558  0.200309\n",
      "2019-02-01  0.687170 -1.457448 -0.318606 -0.936680 -0.633044\n",
      "2019-02-04  0.751901 -0.644338  0.054160  2.028722  0.199912\n",
      "2019-02-05  0.513544 -0.473130 -0.890661 -0.055944 -1.062386\n",
      "2019-02-06 -0.416185 -0.674240 -0.647112  0.141131  0.058555\n",
      "2019-02-07  0.216087  0.577778 -0.704424  1.127284 -1.949853\n",
      "2019-02-08  0.261736 -0.107185 -0.049137  0.189526 -0.512618\n"
     ]
    }
   ],
   "source": [
    "df_xsts_incremental = daily_df_source(entities=dict(cols=['A','B','C','D','E']), period=(datetime(2019,1,20), datetime(2019,2,10)))\n",
    "print(df_xsts_incremental)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another example, let us ask it for data which is a subset of previously generated data - no incremental columns or dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xsts_subset = daily_df_source(entities=dict(cols=['A','B','C','E']), period=(datetime(2019,1,20), datetime(2019,2,1)))\n",
    "print(df_xsts_subset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
