{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we will explore how a CachedSource class works. Specifically, we will take the example of a PanelCachedSource, which outputs a DataFrame which has both time-series and cross-sectional dimensions. Focus on how the class automatically caches data generated during previous calls to the instance of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by importing all the necessay libraries. You may have to change the system path here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\raman\\\\zeroth\\\\zeroth-meta\\\\\")\n",
    "\n",
    "from zpmeta.superclasses.panelcachedsource import PanelCachedSource\n",
    "from zpmeta.metaclasses.singletons import MultitonMeta\n",
    "from pandas import DataFrame, Series, concat, MultiIndex, date_range\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us create a subclass of PanelCachedSource that generates a dataframe of random numbers. All we have to do is to implement the \"execute\" method of the superclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPanelCachedSource(PanelCachedSource, metaclass=MultitonMeta):\n",
    "    '''Subclasses PanelCachedSource to create a dataframe of random numbers.\n",
    "    Accepts a dictionary of parameters, including:\n",
    "    cols: list of column names\n",
    "    '''\n",
    "    def __init__(self, params: dict = None):\n",
    "        super(RandomPanelCachedSource, self).__init__(params)\n",
    "        self.appendable = dict(xs=True, ts=True)\n",
    "    \n",
    "    def execute(self, call_type=None, entities=None, period=None):\n",
    "        cols = MultiIndex.from_product([val for val in entities.values()], names=entities.keys())\n",
    "        idx = date_range(period[0], period[1], freq=self.params['freq'])\n",
    "        result = DataFrame(np.random.randn(len(idx), len(cols)), columns=cols, index=idx)\n",
    "        \n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us insantiate it. Notice how we can set the frequency of data generated in the params while instantiating the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:args: ({'freq': 'B'},) ; kwds: {}\n",
      "INFO:root:Multiton checking registry for key: (<class '__main__.RandomPanelCachedSource'>, '{\"freq\": \"B\"}')\n",
      "INFO:root:Multiton No Instance of <class '__main__.RandomPanelCachedSource'> {\"freq\": \"B\"}\n",
      "INFO:root:Multiton Registering Instance of <class '__main__.RandomPanelCachedSource'> {\"freq\": \"B\"}\n"
     ]
    }
   ],
   "source": [
    "daily_df_source = RandomPanelCachedSource(dict(freq='B'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once instantiated, the instance of this class behaves like a function. A function that has \"memory\". This is a more sophisticated form of memoization.\n",
    "\n",
    "Let us call this function object to create some initial dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RUN RandomPanelCachedSource {'freq': 'B'}\n",
      "INFO:root:RUN INITIAL: [{'Type': ['A', 'B', 'C'], 'ID': [1, 2]}] 2019-01-12 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:EXEC INITIAL: [{'Type': ['A', 'B', 'C'], 'ID': [1, 2]}] 2019-01-12 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:DONE RandomPanelCachedSource {'freq': 'B'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type               A                   B                   C          \n",
      "ID                 1         2         1         2         1         2\n",
      "2019-01-14 -0.323599 -0.021022  0.314629 -2.611771  0.065448  0.498829\n",
      "2019-01-15 -0.680330 -1.223275 -0.735135  2.948655  0.930340 -0.724284\n",
      "2019-01-16  0.258483  0.151749 -0.372498  0.416993 -1.550087  0.207735\n",
      "2019-01-17  1.041824 -0.315572 -0.403987  0.743811 -0.032790 -1.019320\n",
      "2019-01-18 -0.668419  0.349751 -1.574504 -0.661031  0.847232 -1.770366\n",
      "2019-01-21 -0.347372 -0.613787 -0.027499 -0.511402  0.873496 -0.518390\n",
      "2019-01-22  2.208016  0.287923 -0.201551 -0.132711 -0.308634  0.487845\n",
      "2019-01-23 -0.567070 -1.748627  0.202055  1.292627 -0.656767 -1.014372\n",
      "2019-01-24 -0.208159  0.247512 -0.411951 -0.961023 -0.737373 -0.320096\n",
      "2019-01-25 -1.426859 -0.392819  0.832277 -0.716505  0.497544  0.330641\n",
      "2019-01-28 -0.033412 -0.269330 -0.913541 -0.049269 -0.456778  0.386928\n",
      "2019-01-29  1.399672 -0.796335  0.229888  1.513334 -0.520934 -0.791678\n",
      "2019-01-30 -1.034036 -0.547200 -0.502207 -1.218041 -0.442107 -0.128277\n",
      "2019-01-31 -0.525607  1.053791  1.730709  1.243597  0.101991  0.152431\n"
     ]
    }
   ],
   "source": [
    "df = daily_df_source(entities=dict(Type=['A','B','C'], ID=[1,2]), period=(datetime(2019,1,12), datetime(2019,1,31)))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us give it some incremental columns. Notice how the class automatically recognizes the additional columns given and generates data only for that additional column and appends it to the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RUN RandomPanelCachedSource {'freq': 'B'}\n",
      "INFO:root:RUN Nth: {'Type': ['C', 'D'], 'ID': [1, 2]} 2019-01-12 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:INCREMENTAL Items: {'Type': ['D'], 'ID': [1, 2]}\n",
      "INFO:root:TOTAL Items: {'Type': ['C', 'B', 'D', 'A'], 'ID': [1, 2]}\n",
      "INFO:root:DECREMENTAL Items: {}\n",
      "INFO:root:INCREMENTAL Period: None - None\n",
      "INFO:root:TOTAL Period: 2019-01-12 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:APPENDABLE XS:True TS:True\n",
      "INFO:root:EXEC INCREMENTAL XS1: [{'Type': ['D'], 'ID': [1, 2]}] 2019-01-12 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:DONE RandomPanelCachedSource {'freq': 'B'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2019, 1, 12, 0, 0), datetime.datetime(2019, 1, 31, 0, 0))\n",
      "{'Type': ['C', 'D'], 'ID': [1, 2]}\n",
      "Type               A                   B                   C            \\\n",
      "ID                 1         2         1         2         1         2   \n",
      "2019-01-14 -0.323599 -0.021022  0.314629 -2.611771  0.065448  0.498829   \n",
      "2019-01-15 -0.680330 -1.223275 -0.735135  2.948655  0.930340 -0.724284   \n",
      "2019-01-16  0.258483  0.151749 -0.372498  0.416993 -1.550087  0.207735   \n",
      "2019-01-17  1.041824 -0.315572 -0.403987  0.743811 -0.032790 -1.019320   \n",
      "2019-01-18 -0.668419  0.349751 -1.574504 -0.661031  0.847232 -1.770366   \n",
      "2019-01-21 -0.347372 -0.613787 -0.027499 -0.511402  0.873496 -0.518390   \n",
      "2019-01-22  2.208016  0.287923 -0.201551 -0.132711 -0.308634  0.487845   \n",
      "2019-01-23 -0.567070 -1.748627  0.202055  1.292627 -0.656767 -1.014372   \n",
      "2019-01-24 -0.208159  0.247512 -0.411951 -0.961023 -0.737373 -0.320096   \n",
      "2019-01-25 -1.426859 -0.392819  0.832277 -0.716505  0.497544  0.330641   \n",
      "2019-01-28 -0.033412 -0.269330 -0.913541 -0.049269 -0.456778  0.386928   \n",
      "2019-01-29  1.399672 -0.796335  0.229888  1.513334 -0.520934 -0.791678   \n",
      "2019-01-30 -1.034036 -0.547200 -0.502207 -1.218041 -0.442107 -0.128277   \n",
      "2019-01-31 -0.525607  1.053791  1.730709  1.243597  0.101991  0.152431   \n",
      "\n",
      "Type               D            \n",
      "ID                 1         2  \n",
      "2019-01-14 -0.741051 -0.676301  \n",
      "2019-01-15 -0.405813 -0.485499  \n",
      "2019-01-16 -0.653960 -1.351142  \n",
      "2019-01-17  3.300501 -2.249953  \n",
      "2019-01-18  0.211605 -1.006756  \n",
      "2019-01-21  0.658201  0.370444  \n",
      "2019-01-22  0.796281 -2.559423  \n",
      "2019-01-23  0.980196  2.483086  \n",
      "2019-01-24  1.528071  1.824343  \n",
      "2019-01-25  0.475220  0.992709  \n",
      "2019-01-28 -0.896942  0.930663  \n",
      "2019-01-29  2.107772 -1.886505  \n",
      "2019-01-30 -0.149796  0.994744  \n",
      "2019-01-31  0.194620  0.293319  \n"
     ]
    }
   ],
   "source": [
    "df_xs_incremental = daily_df_source(entities=dict(Type=['C', 'D'], ID=[1,2]), period=(datetime(2019,1,12), datetime(2019,1,31)))\n",
    "print(df_xs_incremental)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we give it the same set of columns but additional time period. Now it generates data only for the \"incremental\" period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RUN RandomPanelCachedSource {'freq': 'B'}\n",
      "INFO:root:RUN Nth: {'Type': ['A', 'B', 'C', 'D'], 'ID': [1, 2]} 2019-01-20 00:00:00 - 2019-02-05 00:00:00\n",
      "INFO:root:INCREMENTAL Items: None\n",
      "INFO:root:TOTAL Items: {'Type': ['C', 'D', 'A', 'B'], 'ID': [1, 2]}\n",
      "INFO:root:DECREMENTAL Items: None\n",
      "INFO:root:INCREMENTAL Period: 2019-01-31 00:00:00 - 2019-02-05 00:00:00\n",
      "INFO:root:TOTAL Period: 2019-01-12 00:00:00 - 2019-02-05 00:00:00\n",
      "INFO:root:APPENDABLE XS:True TS:True\n",
      "INFO:root:EXEC INCREMENTAL TS1: [{'Type': ['C', 'B', 'D', 'A'], 'ID': [1, 2]}] 2019-01-31 00:00:00 - 2019-02-05 00:00:00\n",
      "INFO:root:DONE RandomPanelCachedSource {'freq': 'B'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2019, 1, 20, 0, 0), datetime.datetime(2019, 2, 5, 0, 0))\n",
      "{'Type': ['A', 'B', 'C', 'D'], 'ID': [1, 2]}\n",
      "Type               A                   B                   C            \\\n",
      "ID                 1         2         1         2         1         2   \n",
      "2019-01-14 -0.323599 -0.021022  0.314629 -2.611771  0.065448  0.498829   \n",
      "2019-01-15 -0.680330 -1.223275 -0.735135  2.948655  0.930340 -0.724284   \n",
      "2019-01-16  0.258483  0.151749 -0.372498  0.416993 -1.550087  0.207735   \n",
      "2019-01-17  1.041824 -0.315572 -0.403987  0.743811 -0.032790 -1.019320   \n",
      "2019-01-18 -0.668419  0.349751 -1.574504 -0.661031  0.847232 -1.770366   \n",
      "2019-01-21 -0.347372 -0.613787 -0.027499 -0.511402  0.873496 -0.518390   \n",
      "2019-01-22  2.208016  0.287923 -0.201551 -0.132711 -0.308634  0.487845   \n",
      "2019-01-23 -0.567070 -1.748627  0.202055  1.292627 -0.656767 -1.014372   \n",
      "2019-01-24 -0.208159  0.247512 -0.411951 -0.961023 -0.737373 -0.320096   \n",
      "2019-01-25 -1.426859 -0.392819  0.832277 -0.716505  0.497544  0.330641   \n",
      "2019-01-28 -0.033412 -0.269330 -0.913541 -0.049269 -0.456778  0.386928   \n",
      "2019-01-29  1.399672 -0.796335  0.229888  1.513334 -0.520934 -0.791678   \n",
      "2019-01-30 -1.034036 -0.547200 -0.502207 -1.218041 -0.442107 -0.128277   \n",
      "2019-01-31 -0.525607  1.053791  1.730709  1.243597  0.101991  0.152431   \n",
      "2019-02-01 -0.653815 -0.753291  0.482208  0.601541  1.493229  0.159304   \n",
      "2019-02-04  0.306656  1.294785  0.233924 -0.983370 -0.927833 -0.573244   \n",
      "2019-02-05  0.748571  0.357185 -0.296522  0.679201 -0.143947  1.148545   \n",
      "\n",
      "Type               D            \n",
      "ID                 1         2  \n",
      "2019-01-14 -0.741051 -0.676301  \n",
      "2019-01-15 -0.405813 -0.485499  \n",
      "2019-01-16 -0.653960 -1.351142  \n",
      "2019-01-17  3.300501 -2.249953  \n",
      "2019-01-18  0.211605 -1.006756  \n",
      "2019-01-21  0.658201  0.370444  \n",
      "2019-01-22  0.796281 -2.559423  \n",
      "2019-01-23  0.980196  2.483086  \n",
      "2019-01-24  1.528071  1.824343  \n",
      "2019-01-25  0.475220  0.992709  \n",
      "2019-01-28 -0.896942  0.930663  \n",
      "2019-01-29  2.107772 -1.886505  \n",
      "2019-01-30 -0.149796  0.994744  \n",
      "2019-01-31  0.194620  0.293319  \n",
      "2019-02-01  0.864526  1.726416  \n",
      "2019-02-04 -0.659052  1.229359  \n",
      "2019-02-05  0.976467  2.226234  \n"
     ]
    }
   ],
   "source": [
    "df_ts_incremental = daily_df_source(entities=dict(Type=['A','B','C','D'],ID=[1,2]), period=(datetime(2019,1,20), datetime(2019,2,5)))\n",
    "print(df_ts_incremental)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us give it an example where we feed it both additional columns and additional period. As we can see, it will generate data first for only the incremental columns for the existing period, and then incremental dates for all the columns. This helps minimze calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RUN RandomPanelCachedSource {'freq': 'B'}\n",
      "INFO:root:RUN Nth: {'Type': ['A', 'B', 'C', 'D', 'E'], 'ID': [1, 2]} 2019-01-20 00:00:00 - 2019-02-10 00:00:00\n",
      "INFO:root:INCREMENTAL Items: {'Type': ['E'], 'ID': [1, 2]}\n",
      "INFO:root:TOTAL Items: {'Type': ['C', 'D', 'A', 'E', 'B'], 'ID': [1, 2]}\n",
      "INFO:root:DECREMENTAL Items: None\n",
      "INFO:root:INCREMENTAL Period: 2019-02-05 00:00:00 - 2019-02-10 00:00:00\n",
      "INFO:root:TOTAL Period: 2019-01-12 00:00:00 - 2019-02-10 00:00:00\n",
      "INFO:root:APPENDABLE XS:True TS:True\n",
      "INFO:root:EXEC INCREMENTAL XS1: [{'Type': ['E'], 'ID': [1, 2]}] 2019-01-12 00:00:00 - 2019-02-05 00:00:00\n",
      "INFO:root:EXEC INCREMENTAL TS1: [{'Type': ['C', 'D', 'A', 'E', 'B'], 'ID': [1, 2]}] 2019-02-05 00:00:00 - 2019-02-10 00:00:00\n",
      "INFO:root:DONE RandomPanelCachedSource {'freq': 'B'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2019, 1, 20, 0, 0), datetime.datetime(2019, 2, 10, 0, 0))\n",
      "{'Type': ['A', 'B', 'C', 'D', 'E'], 'ID': [1, 2]}\n",
      "Type               A                   B                   C            \\\n",
      "ID                 1         2         1         2         1         2   \n",
      "2019-01-14 -0.323599 -0.021022  0.314629 -2.611771  0.065448  0.498829   \n",
      "2019-01-15 -0.680330 -1.223275 -0.735135  2.948655  0.930340 -0.724284   \n",
      "2019-01-16  0.258483  0.151749 -0.372498  0.416993 -1.550087  0.207735   \n",
      "2019-01-17  1.041824 -0.315572 -0.403987  0.743811 -0.032790 -1.019320   \n",
      "2019-01-18 -0.668419  0.349751 -1.574504 -0.661031  0.847232 -1.770366   \n",
      "2019-01-21 -0.347372 -0.613787 -0.027499 -0.511402  0.873496 -0.518390   \n",
      "2019-01-22  2.208016  0.287923 -0.201551 -0.132711 -0.308634  0.487845   \n",
      "2019-01-23 -0.567070 -1.748627  0.202055  1.292627 -0.656767 -1.014372   \n",
      "2019-01-24 -0.208159  0.247512 -0.411951 -0.961023 -0.737373 -0.320096   \n",
      "2019-01-25 -1.426859 -0.392819  0.832277 -0.716505  0.497544  0.330641   \n",
      "2019-01-28 -0.033412 -0.269330 -0.913541 -0.049269 -0.456778  0.386928   \n",
      "2019-01-29  1.399672 -0.796335  0.229888  1.513334 -0.520934 -0.791678   \n",
      "2019-01-30 -1.034036 -0.547200 -0.502207 -1.218041 -0.442107 -0.128277   \n",
      "2019-01-31 -0.525607  1.053791  1.730709  1.243597  0.101991  0.152431   \n",
      "2019-02-01 -0.653815 -0.753291  0.482208  0.601541  1.493229  0.159304   \n",
      "2019-02-04  0.306656  1.294785  0.233924 -0.983370 -0.927833 -0.573244   \n",
      "2019-02-05  0.748571  0.357185 -0.296522  0.679201 -0.143947  1.148545   \n",
      "2019-02-06 -0.347802  0.074428  0.207350 -0.533184 -0.927723  0.222111   \n",
      "2019-02-07  1.154441  0.820379  0.793821 -0.357621  1.063833 -1.027740   \n",
      "2019-02-08 -1.473899 -1.376426  0.143138 -0.863454 -1.959370 -0.630761   \n",
      "\n",
      "Type               D                   E            \n",
      "ID                 1         2         1         2  \n",
      "2019-01-14 -0.741051 -0.676301 -0.760853 -0.372276  \n",
      "2019-01-15 -0.405813 -0.485499  0.746731  1.682755  \n",
      "2019-01-16 -0.653960 -1.351142  1.136604  0.320973  \n",
      "2019-01-17  3.300501 -2.249953  0.106547  0.707743  \n",
      "2019-01-18  0.211605 -1.006756  1.188170  0.034522  \n",
      "2019-01-21  0.658201  0.370444  0.379711 -0.089568  \n",
      "2019-01-22  0.796281 -2.559423 -1.066944  1.241004  \n",
      "2019-01-23  0.980196  2.483086  0.149454 -0.519556  \n",
      "2019-01-24  1.528071  1.824343 -0.307036  1.090532  \n",
      "2019-01-25  0.475220  0.992709  0.372833 -0.679770  \n",
      "2019-01-28 -0.896942  0.930663 -0.407616 -0.556563  \n",
      "2019-01-29  2.107772 -1.886505  0.913466 -0.175913  \n",
      "2019-01-30 -0.149796  0.994744  0.671020 -1.545060  \n",
      "2019-01-31  0.194620  0.293319 -1.020858  1.281038  \n",
      "2019-02-01  0.864526  1.726416 -0.565278  1.021457  \n",
      "2019-02-04 -0.659052  1.229359  0.081327 -1.228706  \n",
      "2019-02-05  0.976467  2.226234 -0.770692  0.979243  \n",
      "2019-02-06  1.163758 -0.705443 -0.063496  1.175623  \n",
      "2019-02-07  2.218283  2.166402 -0.618397 -0.121231  \n",
      "2019-02-08 -0.823697 -1.199074  1.451167 -0.479546  \n"
     ]
    }
   ],
   "source": [
    "df_xsts_incremental = daily_df_source(entities=dict(Type=['A','B','C','D','E'], ID=[1,2]), period=(datetime(2019,1,20), datetime(2019,2,10)))\n",
    "print(df_xsts_incremental)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another example, let us ask it for data which is a subset of previously generated data - no incremental columns or dates. It should not execute for any data, it will just use the prior generate data to returnt the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RUN RandomPanelCachedSource {'freq': 'B'}\n",
      "INFO:root:RUN Nth: {'Type': ['A', 'B', 'C', 'E'], 'ID': [1, 2]} 2019-01-20 00:00:00 - 2019-02-01 00:00:00\n",
      "INFO:root:INCREMENTAL Items: None\n",
      "INFO:root:TOTAL Items: {'Type': ['C', 'A', 'D', 'E', 'B'], 'ID': [1, 2]}\n",
      "INFO:root:DECREMENTAL Items: {}\n",
      "INFO:root:INCREMENTAL Period: None - None\n",
      "INFO:root:TOTAL Period: 2019-01-12 00:00:00 - 2019-02-10 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2019, 1, 20, 0, 0), datetime.datetime(2019, 2, 1, 0, 0))\n",
      "{'Type': ['A', 'B', 'C', 'E'], 'ID': [1, 2]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:APPENDABLE XS:True TS:True\n",
      "INFO:root:DONE RandomPanelCachedSource {'freq': 'B'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type               A                   B                   C            \\\n",
      "ID                 1         2         1         2         1         2   \n",
      "2019-01-14 -0.323599 -0.021022  0.314629 -2.611771  0.065448  0.498829   \n",
      "2019-01-15 -0.680330 -1.223275 -0.735135  2.948655  0.930340 -0.724284   \n",
      "2019-01-16  0.258483  0.151749 -0.372498  0.416993 -1.550087  0.207735   \n",
      "2019-01-17  1.041824 -0.315572 -0.403987  0.743811 -0.032790 -1.019320   \n",
      "2019-01-18 -0.668419  0.349751 -1.574504 -0.661031  0.847232 -1.770366   \n",
      "2019-01-21 -0.347372 -0.613787 -0.027499 -0.511402  0.873496 -0.518390   \n",
      "2019-01-22  2.208016  0.287923 -0.201551 -0.132711 -0.308634  0.487845   \n",
      "2019-01-23 -0.567070 -1.748627  0.202055  1.292627 -0.656767 -1.014372   \n",
      "2019-01-24 -0.208159  0.247512 -0.411951 -0.961023 -0.737373 -0.320096   \n",
      "2019-01-25 -1.426859 -0.392819  0.832277 -0.716505  0.497544  0.330641   \n",
      "2019-01-28 -0.033412 -0.269330 -0.913541 -0.049269 -0.456778  0.386928   \n",
      "2019-01-29  1.399672 -0.796335  0.229888  1.513334 -0.520934 -0.791678   \n",
      "2019-01-30 -1.034036 -0.547200 -0.502207 -1.218041 -0.442107 -0.128277   \n",
      "2019-01-31 -0.525607  1.053791  1.730709  1.243597  0.101991  0.152431   \n",
      "2019-02-01 -0.653815 -0.753291  0.482208  0.601541  1.493229  0.159304   \n",
      "2019-02-04  0.306656  1.294785  0.233924 -0.983370 -0.927833 -0.573244   \n",
      "2019-02-05  0.748571  0.357185 -0.296522  0.679201 -0.143947  1.148545   \n",
      "2019-02-06 -0.347802  0.074428  0.207350 -0.533184 -0.927723  0.222111   \n",
      "2019-02-07  1.154441  0.820379  0.793821 -0.357621  1.063833 -1.027740   \n",
      "2019-02-08 -1.473899 -1.376426  0.143138 -0.863454 -1.959370 -0.630761   \n",
      "\n",
      "Type               D                   E            \n",
      "ID                 1         2         1         2  \n",
      "2019-01-14 -0.741051 -0.676301 -0.760853 -0.372276  \n",
      "2019-01-15 -0.405813 -0.485499  0.746731  1.682755  \n",
      "2019-01-16 -0.653960 -1.351142  1.136604  0.320973  \n",
      "2019-01-17  3.300501 -2.249953  0.106547  0.707743  \n",
      "2019-01-18  0.211605 -1.006756  1.188170  0.034522  \n",
      "2019-01-21  0.658201  0.370444  0.379711 -0.089568  \n",
      "2019-01-22  0.796281 -2.559423 -1.066944  1.241004  \n",
      "2019-01-23  0.980196  2.483086  0.149454 -0.519556  \n",
      "2019-01-24  1.528071  1.824343 -0.307036  1.090532  \n",
      "2019-01-25  0.475220  0.992709  0.372833 -0.679770  \n",
      "2019-01-28 -0.896942  0.930663 -0.407616 -0.556563  \n",
      "2019-01-29  2.107772 -1.886505  0.913466 -0.175913  \n",
      "2019-01-30 -0.149796  0.994744  0.671020 -1.545060  \n",
      "2019-01-31  0.194620  0.293319 -1.020858  1.281038  \n",
      "2019-02-01  0.864526  1.726416 -0.565278  1.021457  \n",
      "2019-02-04 -0.659052  1.229359  0.081327 -1.228706  \n",
      "2019-02-05  0.976467  2.226234 -0.770692  0.979243  \n",
      "2019-02-06  1.163758 -0.705443 -0.063496  1.175623  \n",
      "2019-02-07  2.218283  2.166402 -0.618397 -0.121231  \n",
      "2019-02-08 -0.823697 -1.199074  1.451167 -0.479546  \n"
     ]
    }
   ],
   "source": [
    "df_xsts_subset = daily_df_source(entities=dict(Type=['A','B','C','E'], ID=[1,2]), period=(datetime(2019,1,20), datetime(2019,2,1)))\n",
    "print(df_xsts_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When combined with the MultitonMeta metaclass, this becomes even more powerful, leading to significant efficiencies and resuability of data in a complex simuation. Examples of using the MultitonMeta metaclass follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first try to instantiate another object RandomPanelCachedSource with the same params. As can be seen here, it found the prior instance in the registry and returns us the same instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:args: () ; kwds: {'params': {'freq': 'B'}}\n",
      "INFO:root:Multiton checking registry for key: (<class '__main__.RandomPanelCachedSource'>, '{\"freq\": \"B\"}')\n",
      "INFO:root:Multiton Found Instance of <class '__main__.RandomPanelCachedSource'> {\"freq\": \"B\"}\n"
     ]
    }
   ],
   "source": [
    "daily_df_source_new = RandomPanelCachedSource(params=dict(freq='B'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prior instance already has the data in its cache, let us check for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RUN RandomPanelCachedSource {'freq': 'B'}\n",
      "INFO:root:RUN Nth: {'Type': ['A', 'B', 'C', 'E'], 'ID': [1, 2]} 2019-01-20 00:00:00 - 2019-02-01 00:00:00\n",
      "INFO:root:INCREMENTAL Items: None\n",
      "INFO:root:TOTAL Items: {'Type': ['C', 'A', 'D', 'E', 'B'], 'ID': [1, 2]}\n",
      "INFO:root:DECREMENTAL Items: {}\n",
      "INFO:root:INCREMENTAL Period: None - None\n",
      "INFO:root:TOTAL Period: 2019-01-12 00:00:00 - 2019-02-10 00:00:00\n",
      "INFO:root:APPENDABLE XS:True TS:True\n",
      "INFO:root:DONE RandomPanelCachedSource {'freq': 'B'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2019, 1, 20, 0, 0), datetime.datetime(2019, 2, 1, 0, 0))\n",
      "{'Type': ['A', 'B', 'C', 'E'], 'ID': [1, 2]}\n",
      "Type               A                   B                   C            \\\n",
      "ID                 1         2         1         2         1         2   \n",
      "2019-01-14 -0.323599 -0.021022  0.314629 -2.611771  0.065448  0.498829   \n",
      "2019-01-15 -0.680330 -1.223275 -0.735135  2.948655  0.930340 -0.724284   \n",
      "2019-01-16  0.258483  0.151749 -0.372498  0.416993 -1.550087  0.207735   \n",
      "2019-01-17  1.041824 -0.315572 -0.403987  0.743811 -0.032790 -1.019320   \n",
      "2019-01-18 -0.668419  0.349751 -1.574504 -0.661031  0.847232 -1.770366   \n",
      "2019-01-21 -0.347372 -0.613787 -0.027499 -0.511402  0.873496 -0.518390   \n",
      "2019-01-22  2.208016  0.287923 -0.201551 -0.132711 -0.308634  0.487845   \n",
      "2019-01-23 -0.567070 -1.748627  0.202055  1.292627 -0.656767 -1.014372   \n",
      "2019-01-24 -0.208159  0.247512 -0.411951 -0.961023 -0.737373 -0.320096   \n",
      "2019-01-25 -1.426859 -0.392819  0.832277 -0.716505  0.497544  0.330641   \n",
      "2019-01-28 -0.033412 -0.269330 -0.913541 -0.049269 -0.456778  0.386928   \n",
      "2019-01-29  1.399672 -0.796335  0.229888  1.513334 -0.520934 -0.791678   \n",
      "2019-01-30 -1.034036 -0.547200 -0.502207 -1.218041 -0.442107 -0.128277   \n",
      "2019-01-31 -0.525607  1.053791  1.730709  1.243597  0.101991  0.152431   \n",
      "2019-02-01 -0.653815 -0.753291  0.482208  0.601541  1.493229  0.159304   \n",
      "2019-02-04  0.306656  1.294785  0.233924 -0.983370 -0.927833 -0.573244   \n",
      "2019-02-05  0.748571  0.357185 -0.296522  0.679201 -0.143947  1.148545   \n",
      "2019-02-06 -0.347802  0.074428  0.207350 -0.533184 -0.927723  0.222111   \n",
      "2019-02-07  1.154441  0.820379  0.793821 -0.357621  1.063833 -1.027740   \n",
      "2019-02-08 -1.473899 -1.376426  0.143138 -0.863454 -1.959370 -0.630761   \n",
      "\n",
      "Type               D                   E            \n",
      "ID                 1         2         1         2  \n",
      "2019-01-14 -0.741051 -0.676301 -0.760853 -0.372276  \n",
      "2019-01-15 -0.405813 -0.485499  0.746731  1.682755  \n",
      "2019-01-16 -0.653960 -1.351142  1.136604  0.320973  \n",
      "2019-01-17  3.300501 -2.249953  0.106547  0.707743  \n",
      "2019-01-18  0.211605 -1.006756  1.188170  0.034522  \n",
      "2019-01-21  0.658201  0.370444  0.379711 -0.089568  \n",
      "2019-01-22  0.796281 -2.559423 -1.066944  1.241004  \n",
      "2019-01-23  0.980196  2.483086  0.149454 -0.519556  \n",
      "2019-01-24  1.528071  1.824343 -0.307036  1.090532  \n",
      "2019-01-25  0.475220  0.992709  0.372833 -0.679770  \n",
      "2019-01-28 -0.896942  0.930663 -0.407616 -0.556563  \n",
      "2019-01-29  2.107772 -1.886505  0.913466 -0.175913  \n",
      "2019-01-30 -0.149796  0.994744  0.671020 -1.545060  \n",
      "2019-01-31  0.194620  0.293319 -1.020858  1.281038  \n",
      "2019-02-01  0.864526  1.726416 -0.565278  1.021457  \n",
      "2019-02-04 -0.659052  1.229359  0.081327 -1.228706  \n",
      "2019-02-05  0.976467  2.226234 -0.770692  0.979243  \n",
      "2019-02-06  1.163758 -0.705443 -0.063496  1.175623  \n",
      "2019-02-07  2.218283  2.166402 -0.618397 -0.121231  \n",
      "2019-02-08 -0.823697 -1.199074  1.451167 -0.479546  \n"
     ]
    }
   ],
   "source": [
    "df_xsts_subset_2 = daily_df_source_new(entities=dict(Type=['A','B','C','E'], ID=[1,2]), period=(datetime(2019,1,20), datetime(2019,2,1)))\n",
    "print(df_xsts_subset_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No additional execution was necessary.\n",
    "\n",
    "Now let us create an instance of RandomPanelCachedSource but with a different set of params for annual data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:args: () ; kwds: {'params': {'freq': 'A'}}\n",
      "INFO:root:Multiton checking registry for key: (<class '__main__.RandomPanelCachedSource'>, '{\"freq\": \"A\"}')\n",
      "INFO:root:Multiton No Instance of <class '__main__.RandomPanelCachedSource'> {\"freq\": \"A\"}\n",
      "INFO:root:Multiton Registering Instance of <class '__main__.RandomPanelCachedSource'> {\"freq\": \"A\"}\n"
     ]
    }
   ],
   "source": [
    "annual_df_source = RandomPanelCachedSource(params=dict(freq='A'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
