{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching with PanelSource and MultitonMeta\n",
    "In this file we will explore how a PanelSource class works. Specifically, we will take the example of a Su, which outputs a DataFrame which has both time-series and cross-sectional dimensions. Focus on how the class automatically caches data generated during previous calls to the instance of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by importing all the necessary libraries. You may have to change the system path here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T22:47:46.443463700Z",
     "start_time": "2023-12-02T22:47:45.282347300Z"
    }
   },
   "outputs": [],
   "source": [
    "from zpmeta.sources.panelsource import PanelSource\n",
    "from zpmeta.singletons.singletons import MultitonMeta\n",
    "from pandas import DataFrame, Series, concat, MultiIndex, date_range, IndexSlice\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us create a subclass of Su that generates a dataframe of random numbers. All we have to do is to implement the \"execute\" method of the superclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T22:47:46.479343700Z",
     "start_time": "2023-12-02T22:47:46.453432900Z"
    }
   },
   "outputs": [],
   "source": [
    "class RandomSu(PanelSource, metaclass=MultitonMeta):\n",
    "    '''Subclasses Su to create a dataframe of random numbers.\n",
    "    Accepts a dictionary of parameters, including:\n",
    "    cols: list of column names\n",
    "    '''\n",
    "    _appendable = dict(xs=True, ts=True)\n",
    "    \n",
    "    def _execute(self, call_type=None, entities=None, period=None):\n",
    "        cols = MultiIndex.from_product([val for val in entities.values()], names=entities.keys())\n",
    "        idx = date_range(period[0], period[1], freq=self.params['freq'])\n",
    "        result = DataFrame(np.random.randn(len(idx), len(cols)), columns=cols, index=idx)\n",
    "        \n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us instantiate it. Notice how we can set the frequency of data generated in the params while instantiating the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T22:47:46.626064600Z",
     "start_time": "2023-12-02T22:47:46.477350500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:args: () ; kwds: {'params': {'freq': 'B'}}\n",
      "INFO:root:Multiton checking registry for key: (<class '__main__.RandomSu'>, '{\"params\": {\"freq\": \"B\"}}')\n",
      "INFO:root:Multiton No Instance of <class '__main__.RandomSu'> {\"params\": {\"freq\": \"B\"}}\n",
      "INFO:root:Multiton Registering Instance of <class '__main__.RandomSu'> {\"params\": {\"freq\": \"B\"}}\n"
     ]
    }
   ],
   "source": [
    "daily_df_source = RandomSu(params=dict(freq='B'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once instantiated, the instance of this class behaves like a function. A function that has \"memory\". This is a more sophisticated form of memoization.\n",
    "\n",
    "Let us call this function object to create some initial dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T22:47:46.628057500Z",
     "start_time": "2023-12-02T22:47:46.509243700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RUN RandomSu {'freq': 'B'}\n",
      "INFO:root:RUN INITIAL: [{'Type': ['A', 'B', 'C'], 'ID': [1, 2]}] 2019-01-12 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:EXEC INITIAL: [{'Type': ['A', 'B', 'C'], 'ID': [1, 2]}] 2019-01-12 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:DONE RandomSu {'freq': 'B'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type               A                   B                   C          \n",
      "ID                 1         2         1         2         1         2\n",
      "2019-01-14 -0.113589  1.127684 -0.425210  0.090671 -0.683757 -1.602456\n",
      "2019-01-15 -0.945201  0.070418 -0.655966 -0.351708  2.257358 -1.421704\n",
      "2019-01-16 -0.406979  0.357922 -1.378429 -1.163527 -1.040953  1.017062\n",
      "2019-01-17  0.173099  0.976578 -1.965628 -0.732950  0.186258 -0.864349\n",
      "2019-01-18 -0.513780  0.343738  0.819087 -0.684189  1.479855  1.892667\n",
      "2019-01-21 -0.817289 -0.133922 -0.847299  0.566611  0.569337 -0.307188\n",
      "2019-01-22 -0.303030  0.147259 -0.158122  0.955804  1.199698  0.346873\n",
      "2019-01-23  1.400057 -0.480437  2.117858  1.026802 -0.811281  0.218896\n",
      "2019-01-24  0.221238  0.804325  0.981598 -0.370401  0.352303  0.568744\n",
      "2019-01-25  0.133674 -1.121936  0.650222 -0.981805 -0.127501 -0.906032\n",
      "2019-01-28  1.165822 -0.571892 -1.292981  0.145317  0.007182 -0.194428\n",
      "2019-01-29  0.513804  0.487645  0.565450  0.245766 -0.256470  1.493737\n",
      "2019-01-30  2.587689  0.571956 -1.666442  2.102605 -0.695233 -1.136176\n",
      "2019-01-31  0.372582  1.764793  0.377430 -0.878421 -1.169615 -1.014280\n"
     ]
    }
   ],
   "source": [
    "df = daily_df_source(entities=dict(Type=['A','B','C'], ID=[1,2]), period=(datetime(2019,1,12), datetime(2019,1,31)))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us give it some incremental columns. Notice how the class automatically recognizes the additional columns given and generates data only for that additional column and appends it to the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T22:47:46.678384Z",
     "start_time": "2023-12-02T22:47:46.560074Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RUN RandomSu {'freq': 'B'}\n",
      "INFO:root:RUN Nth: {'Type': ['C', 'D'], 'ID': [1, 2]} 2019-01-12 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:INCREMENTAL Items: {'Type': ['D'], 'ID': [1, 2]}\n",
      "INFO:root:TOTAL Items: {'Type': ['D', 'C', 'A', 'B'], 'ID': [1, 2]}\n",
      "INFO:root:DECREMENTAL Items: {}\n",
      "INFO:root:INCREMENTAL Period: None - None\n",
      "INFO:root:TOTAL Period: 2019-01-12 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:APPENDABLE XS:True TS:True\n",
      "INFO:root:EXEC INCREMENTAL XS1: [{'Type': ['D'], 'ID': [1, 2]}] 2019-01-12 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:DONE RandomSu {'freq': 'B'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "df_xs_incremental = daily_df_source(entities=dict(Type=['C', 'D'], ID=[1,2]), period=(datetime(2019,1,12), datetime(2019,1,31)))\n",
    "print(df_xs_incremental)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we give it the same set of columns but additional time period. Now it generates data only for the \"incremental\" period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T22:47:47.026247700Z",
     "start_time": "2023-12-02T22:47:46.601794400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RUN RandomSu {'freq': 'B'}\n",
      "INFO:root:RUN INITIAL: [{'Type': ['A', 'B', 'C', 'D'], 'ID': [1, 2]}] 2019-01-20 00:00:00 - 2019-02-05 00:00:00\n",
      "INFO:root:EXEC INITIAL: [{'Type': ['A', 'B', 'C', 'D'], 'ID': [1, 2]}] 2019-01-20 00:00:00 - 2019-02-05 00:00:00\n",
      "INFO:root:DONE RandomSu {'freq': 'B'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type               A                   B                   C            \\\n",
      "ID                 1         2         1         2         1         2   \n",
      "2019-01-21  0.291468  0.144811  0.219353 -0.694899  1.221999  1.128885   \n",
      "2019-01-22  1.324409 -0.415895  1.324625  1.586012 -0.548481  0.043651   \n",
      "2019-01-23  0.688719 -0.814662  1.241875  0.045986 -0.447418  0.506325   \n",
      "2019-01-24 -0.070301  0.019660 -0.306092  1.136743 -0.036766 -0.607202   \n",
      "2019-01-25  1.005094  0.230973  1.793772  0.643682 -0.042197  0.717138   \n",
      "2019-01-28  1.330388  2.484320  1.624623  0.506643  0.021312  0.193877   \n",
      "2019-01-29 -0.255180 -0.050188 -1.259297  0.716407  0.187235  0.126505   \n",
      "2019-01-30 -0.967916 -0.351965 -0.734921 -0.377098 -1.017045  0.008172   \n",
      "2019-01-31  0.113475 -1.013812 -0.004875 -1.119156  1.189673 -0.505255   \n",
      "2019-02-01 -0.759758 -1.750040  1.194653  1.464802 -0.083039 -1.105587   \n",
      "2019-02-04  0.310569 -0.507014 -1.119550 -1.468665  0.674651 -0.248070   \n",
      "2019-02-05 -0.263937  0.175136 -0.798066 -1.937027  1.315412 -0.683655   \n",
      "\n",
      "Type               D            \n",
      "ID                 1         2  \n",
      "2019-01-21 -1.303027  2.346120  \n",
      "2019-01-22 -0.688462  1.736322  \n",
      "2019-01-23  0.737845 -0.729888  \n",
      "2019-01-24 -0.014569 -0.843453  \n",
      "2019-01-25  1.262399 -0.586840  \n",
      "2019-01-28 -0.769456  0.316019  \n",
      "2019-01-29  1.243380  0.860344  \n",
      "2019-01-30  0.507079  0.262959  \n",
      "2019-01-31  0.519409  0.325635  \n",
      "2019-02-01  0.684940  0.223248  \n",
      "2019-02-04  1.606338  0.984742  \n",
      "2019-02-05  0.340518  0.440009  \n"
     ]
    }
   ],
   "source": [
    "df_ts_incremental = daily_df_source(entities=dict(Type=['A','B','C','D'],ID=[1,2]), period=(datetime(2019,1,20), datetime(2019,2,5)))\n",
    "print(df_ts_incremental)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us give it an example where we feed it both additional columns and additional period. As we can see, it will generate data first for only the incremental columns for the existing period, and then incremental dates for all the columns. This helps minimze calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T22:47:47.152823100Z",
     "start_time": "2023-12-02T22:47:46.649812300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RUN RandomSu {'freq': 'B'}\n",
      "INFO:root:RUN Nth: {'Type': ['A', 'B', 'C', 'D', 'E'], 'ID': [1, 2]} 2019-01-20 00:00:00 - 2019-02-10 00:00:00\n",
      "INFO:root:INCREMENTAL Items: {'Type': ['E'], 'ID': [1, 2]}\n",
      "INFO:root:TOTAL Items: {'Type': ['D', 'E', 'B', 'C', 'A'], 'ID': [1, 2]}\n",
      "INFO:root:DECREMENTAL Items: None\n",
      "INFO:root:INCREMENTAL Period: 2019-02-05 00:00:00 - 2019-02-10 00:00:00\n",
      "INFO:root:TOTAL Period: 2019-01-20 00:00:00 - 2019-02-10 00:00:00\n",
      "INFO:root:APPENDABLE XS:True TS:True\n",
      "INFO:root:EXEC INCREMENTAL XS1: [{'Type': ['E'], 'ID': [1, 2]}] 2019-01-20 00:00:00 - 2019-02-05 00:00:00\n",
      "INFO:root:EXEC INCREMENTAL TS1: [{'Type': ['D', 'E', 'B', 'C', 'A'], 'ID': [1, 2]}] 2019-02-05 00:00:00 - 2019-02-10 00:00:00\n",
      "INFO:root:DONE RandomSu {'freq': 'B'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type               D                   E                   B            \\\n",
      "ID                 1         2         1         2         1         2   \n",
      "2019-02-05  0.041553 -1.528800 -1.068862  0.488556 -0.070887  0.749038   \n",
      "2019-02-06  0.407147  0.155818  1.868483 -0.948123  0.265276 -1.257401   \n",
      "2019-02-07  0.092758  0.974562 -1.075754 -0.577542 -0.581040  0.966101   \n",
      "2019-02-08 -0.856259  0.937009 -2.511874  0.226069 -0.972299 -0.323508   \n",
      "\n",
      "Type               C                   A            \n",
      "ID                 1         2         1         2  \n",
      "2019-02-05  0.498114  0.227783  0.242945 -0.732580  \n",
      "2019-02-06 -0.199864  0.679090  0.430896  0.419969  \n",
      "2019-02-07 -0.568589  0.616249  0.168297  0.234796  \n",
      "2019-02-08  1.750102 -0.715190  2.008337 -1.583508  \n"
     ]
    }
   ],
   "source": [
    "df_xsts_incremental = daily_df_source(entities=dict(Type=['A','B','C','D','E'], ID=[1,2]), period=(datetime(2019,1,20), datetime(2019,2,10)))\n",
    "print(df_xsts_incremental)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another example, let us ask it for data which is a subset of previously generated data - no incremental columns or dates. It should not execute for any data, it will just use the prior generate data to returnt the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T22:47:47.155813Z",
     "start_time": "2023-12-02T22:47:46.728433400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RUN RandomSu {'freq': 'B'}\n",
      "INFO:root:RUN Nth: {'Type': ['A', 'B', 'C', 'E'], 'ID': [1, 2]} 2019-01-20 00:00:00 - 2019-02-01 00:00:00\n",
      "INFO:root:INCREMENTAL Items: None\n",
      "INFO:root:TOTAL Items: {'Type': ['D', 'E', 'B', 'C', 'A'], 'ID': [1, 2]}\n",
      "INFO:root:DECREMENTAL Items: {}\n",
      "INFO:root:INCREMENTAL Period: None - None\n",
      "INFO:root:TOTAL Period: 2019-01-20 00:00:00 - 2019-02-10 00:00:00\n",
      "INFO:root:APPENDABLE XS:True TS:True\n",
      "INFO:root:DONE RandomSu {'freq': 'B'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type               D                   E                   B            \\\n",
      "ID                 1         2         1         2         1         2   \n",
      "2019-02-05  0.041553 -1.528800 -1.068862  0.488556 -0.070887  0.749038   \n",
      "2019-02-06  0.407147  0.155818  1.868483 -0.948123  0.265276 -1.257401   \n",
      "2019-02-07  0.092758  0.974562 -1.075754 -0.577542 -0.581040  0.966101   \n",
      "2019-02-08 -0.856259  0.937009 -2.511874  0.226069 -0.972299 -0.323508   \n",
      "\n",
      "Type               C                   A            \n",
      "ID                 1         2         1         2  \n",
      "2019-02-05  0.498114  0.227783  0.242945 -0.732580  \n",
      "2019-02-06 -0.199864  0.679090  0.430896  0.419969  \n",
      "2019-02-07 -0.568589  0.616249  0.168297  0.234796  \n",
      "2019-02-08  1.750102 -0.715190  2.008337 -1.583508  \n"
     ]
    }
   ],
   "source": [
    "df_xsts_subset = daily_df_source(entities=dict(Type=['A','B','C','E'], ID=[1,2]), period=(datetime(2019,1,20), datetime(2019,2,1)))\n",
    "print(df_xsts_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When combined with the MultitonMeta metaclass, this becomes even more powerful, leading to significant efficiencies and resuability of data in a complex simuation. Examples of using the MultitonMeta metaclass follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first try to instantiate another object RandomSu with the same params. As can be seen here, it found the prior instance in the registry and returns us the same instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T22:47:47.156809700Z",
     "start_time": "2023-12-02T22:47:46.788015900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:args: () ; kwds: {'params': {'freq': 'B'}}\n",
      "INFO:root:Multiton checking registry for key: (<class '__main__.RandomSu'>, '{\"params\": {\"freq\": \"B\"}}')\n",
      "INFO:root:Multiton Found Instance of <class '__main__.RandomSu'> {\"params\": {\"freq\": \"B\"}}\n"
     ]
    }
   ],
   "source": [
    "daily_df_source_new = RandomSu(params=dict(freq='B'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prior instance already has the data in its cache, let us check for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T22:47:47.161873300Z",
     "start_time": "2023-12-02T22:47:46.819894600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RUN RandomSu {'freq': 'B'}\n",
      "INFO:root:RUN Nth: {'Type': ['A', 'B', 'C', 'E'], 'ID': [1, 2]} 2019-01-20 00:00:00 - 2019-02-01 00:00:00\n",
      "INFO:root:INCREMENTAL Items: None\n",
      "INFO:root:TOTAL Items: {'Type': ['D', 'E', 'B', 'C', 'A'], 'ID': [1, 2]}\n",
      "INFO:root:DECREMENTAL Items: {}\n",
      "INFO:root:INCREMENTAL Period: None - None\n",
      "INFO:root:TOTAL Period: 2019-01-20 00:00:00 - 2019-02-10 00:00:00\n",
      "INFO:root:APPENDABLE XS:True TS:True\n",
      "INFO:root:DONE RandomSu {'freq': 'B'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type               D                   E                   B            \\\n",
      "ID                 1         2         1         2         1         2   \n",
      "2019-02-05  0.041553 -1.528800 -1.068862  0.488556 -0.070887  0.749038   \n",
      "2019-02-06  0.407147  0.155818  1.868483 -0.948123  0.265276 -1.257401   \n",
      "2019-02-07  0.092758  0.974562 -1.075754 -0.577542 -0.581040  0.966101   \n",
      "2019-02-08 -0.856259  0.937009 -2.511874  0.226069 -0.972299 -0.323508   \n",
      "\n",
      "Type               C                   A            \n",
      "ID                 1         2         1         2  \n",
      "2019-02-05  0.498114  0.227783  0.242945 -0.732580  \n",
      "2019-02-06 -0.199864  0.679090  0.430896  0.419969  \n",
      "2019-02-07 -0.568589  0.616249  0.168297  0.234796  \n",
      "2019-02-08  1.750102 -0.715190  2.008337 -1.583508  \n"
     ]
    }
   ],
   "source": [
    "df_xsts_subset_2 = daily_df_source_new(entities=dict(Type=['A','B','C','E'], ID=[1,2]), period=(datetime(2019,1,20), datetime(2019,2,1)))\n",
    "print(df_xsts_subset_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No additional execution was necessary.\n",
    "\n",
    "Now let us create an instance of RandomSu but with a different set of params for annual data generation. It will not find the class in the registry and will create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T22:47:47.412174400Z",
     "start_time": "2023-12-02T22:47:46.867776200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:args: () ; kwds: {'params': {'freq': 'A'}}\n",
      "INFO:root:Multiton checking registry for key: (<class '__main__.RandomSu'>, '{\"params\": {\"freq\": \"A\"}}')\n",
      "INFO:root:Multiton No Instance of <class '__main__.RandomSu'> {\"params\": {\"freq\": \"A\"}}\n",
      "INFO:root:Multiton Registering Instance of <class '__main__.RandomSu'> {\"params\": {\"freq\": \"A\"}}\n"
     ]
    }
   ],
   "source": [
    "annual_df_source = RandomSu(params=dict(freq='A'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, wherever in the code an annual RandomSu is instantiated, it will access the same instance which also has the data for all the prior calls saved in it."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Refreshing the cache\n",
    "Sometimes we might e in a situation, where we want to refresh the last few rows of the cached data everytime we need make a call. Think of a live-trading or an online system for example, where the data in the database may be updated after an initial entry. For this we have to set the 'caching' parameter dict while instantiating the class. Then we can mention for how many periods the data will need to be refreshed. Let us look at an example."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:args: () ; kwds: {'params': {'freq': 'B'}, 'caching': {'ts_anchor': 'cache', 'ts_refresh': 2}}\n",
      "INFO:root:Multiton checking registry for key: (<class '__main__.RandomSu'>, '{\"caching\": {\"ts_anchor\": \"cache\", \"ts_refresh\": 2}, \"params\": {\"freq\": \"B\"}}')\n",
      "INFO:root:Multiton No Instance of <class '__main__.RandomSu'> {\"caching\": {\"ts_anchor\": \"cache\", \"ts_refresh\": 2}, \"params\": {\"freq\": \"B\"}}\n",
      "INFO:root:Multiton Registering Instance of <class '__main__.RandomSu'> {\"caching\": {\"ts_anchor\": \"cache\", \"ts_refresh\": 2}, \"params\": {\"freq\": \"B\"}}\n",
      "INFO:root:RUN RandomSu {'freq': 'B'}\n",
      "INFO:root:RUN INITIAL: [{'Type': ['A', 'B', 'C'], 'ID': [1, 2]}] 2019-01-12 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:EXEC INITIAL: [{'Type': ['A', 'B', 'C'], 'ID': [1, 2]}] 2019-01-12 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:DONE RandomSu {'freq': 'B'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type               A                   B                   C          \n",
      "ID                 1         2         1         2         1         2\n",
      "2019-01-14 -1.860632  0.591817  1.065688 -0.521971 -0.365940  0.174923\n",
      "2019-01-15 -0.451329  1.105575 -1.302726 -0.260153 -1.644813 -1.388995\n",
      "2019-01-16  0.749883 -0.658047 -0.257758 -0.100584 -0.999681  1.019733\n",
      "2019-01-17 -0.782119  0.088730 -2.116978  1.109668 -0.644203 -0.228887\n",
      "2019-01-18  0.569310 -0.769615 -1.136831 -0.948201  0.332714 -0.641188\n",
      "2019-01-21  0.199768  0.349603  1.412867  2.387307  0.692177 -0.784905\n",
      "2019-01-22 -0.570967  0.319126  0.257885  0.592910 -0.588269  1.143655\n",
      "2019-01-23  1.499787  0.707194  1.178393  0.328974  0.129723  0.163481\n",
      "2019-01-24  0.009799 -0.163553 -0.837591 -0.724882 -0.264518  0.670216\n",
      "2019-01-25  0.718019  0.467600  0.961503  0.287439  0.602721 -0.130074\n",
      "2019-01-28  0.506791 -0.789897 -0.823635  0.232176  0.684665  0.440938\n",
      "2019-01-29 -0.272146 -0.813697  0.411256 -1.371706  1.563803  1.623825\n",
      "2019-01-30  0.954333  0.852629  0.608503  0.923953  1.250685  0.790388\n",
      "2019-01-31  0.878101  0.289801  0.067902 -0.261307  0.498061 -0.646756\n"
     ]
    }
   ],
   "source": [
    "# instantiate with proper caching parameters (here it will refresh last two periods of data\n",
    "refreshed_df_source = RandomSu(params=dict(freq='B'), caching=dict(ts_anchor='cache', ts_refresh=2))\n",
    "\n",
    "# fill initial data\n",
    "df = refreshed_df_source(entities=dict(Type=['A','B','C'], ID=[1,2]), period=(datetime(2019,1,12), datetime(2019,1,31)))\n",
    "print(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:47:47.415164600Z",
     "start_time": "2023-12-02T22:47:46.921596600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us check the 'period' attribute of the instance. It will show us the period for which the data is cached adjusted for the refresh period."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2019, 1, 12, 0, 0), Timestamp('2019-01-29 00:00:00', freq='B'))\n",
      "Type               A                   B                   C          \n",
      "ID                 1         2         1         2         1         2\n",
      "2019-01-14 -1.860632  0.591817  1.065688 -0.521971 -0.365940  0.174923\n",
      "2019-01-15 -0.451329  1.105575 -1.302726 -0.260153 -1.644813 -1.388995\n",
      "2019-01-16  0.749883 -0.658047 -0.257758 -0.100584 -0.999681  1.019733\n",
      "2019-01-17 -0.782119  0.088730 -2.116978  1.109668 -0.644203 -0.228887\n",
      "2019-01-18  0.569310 -0.769615 -1.136831 -0.948201  0.332714 -0.641188\n",
      "2019-01-21  0.199768  0.349603  1.412867  2.387307  0.692177 -0.784905\n",
      "2019-01-22 -0.570967  0.319126  0.257885  0.592910 -0.588269  1.143655\n",
      "2019-01-23  1.499787  0.707194  1.178393  0.328974  0.129723  0.163481\n",
      "2019-01-24  0.009799 -0.163553 -0.837591 -0.724882 -0.264518  0.670216\n",
      "2019-01-25  0.718019  0.467600  0.961503  0.287439  0.602721 -0.130074\n",
      "2019-01-28  0.506791 -0.789897 -0.823635  0.232176  0.684665  0.440938\n",
      "2019-01-29 -0.272146 -0.813697  0.411256 -1.371706  1.563803  1.623825\n",
      "2019-01-30  0.954333  0.852629  0.608503  0.923953  1.250685  0.790388\n",
      "2019-01-31  0.878101  0.289801  0.067902 -0.261307  0.498061 -0.646756\n"
     ]
    }
   ],
   "source": [
    "print(refreshed_df_source.period)\n",
    "print(refreshed_df_source.value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:47:47.416160900Z",
     "start_time": "2023-12-02T22:47:46.987377200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RUN RandomSu {'freq': 'B'}\n",
      "INFO:root:RUN Nth: {'Type': ['A', 'B', 'C'], 'ID': [1, 2]} 2019-01-12 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:INCREMENTAL Items: None\n",
      "INFO:root:TOTAL Items: {'Type': ['C', 'A', 'B'], 'ID': [1, 2]}\n",
      "INFO:root:DECREMENTAL Items: None\n",
      "INFO:root:INCREMENTAL Period: 2019-01-29 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:TOTAL Period: 2019-01-12 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:APPENDABLE XS:True TS:True\n",
      "INFO:root:EXEC INCREMENTAL TS1: [{'Type': ['A', 'B', 'C'], 'ID': [1, 2]}] 2019-01-29 00:00:00 - 2019-01-31 00:00:00\n",
      "INFO:root:DONE RandomSu {'freq': 'B'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type               A                   B                   C          \n",
      "ID                 1         2         1         2         1         2\n",
      "2019-01-14 -1.860632  0.591817  1.065688 -0.521971 -0.365940  0.174923\n",
      "2019-01-15 -0.451329  1.105575 -1.302726 -0.260153 -1.644813 -1.388995\n",
      "2019-01-16  0.749883 -0.658047 -0.257758 -0.100584 -0.999681  1.019733\n",
      "2019-01-17 -0.782119  0.088730 -2.116978  1.109668 -0.644203 -0.228887\n",
      "2019-01-18  0.569310 -0.769615 -1.136831 -0.948201  0.332714 -0.641188\n",
      "2019-01-21  0.199768  0.349603  1.412867  2.387307  0.692177 -0.784905\n",
      "2019-01-22 -0.570967  0.319126  0.257885  0.592910 -0.588269  1.143655\n",
      "2019-01-23  1.499787  0.707194  1.178393  0.328974  0.129723  0.163481\n",
      "2019-01-24  0.009799 -0.163553 -0.837591 -0.724882 -0.264518  0.670216\n",
      "2019-01-25  0.718019  0.467600  0.961503  0.287439  0.602721 -0.130074\n",
      "2019-01-28  0.506791 -0.789897 -0.823635  0.232176  0.684665  0.440938\n",
      "2019-01-29 -0.272146 -0.813697  0.411256 -1.371706  1.563803  1.623825\n",
      "2019-01-30  0.954333  0.852629  0.608503  0.923953  1.250685  0.790388\n",
      "2019-01-31  0.878101  0.289801  0.067902 -0.261307  0.498061 -0.646756\n"
     ]
    }
   ],
   "source": [
    "df_refreshed = refreshed_df_source(entities=dict(Type=['A','B','C'], ID=[1,2]), period=(datetime(2019,1,12), datetime(2019,1,31)))\n",
    "print(df_refreshed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:47:47.634431500Z",
     "start_time": "2023-12-02T22:47:47.026247700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:47:47.635428400Z",
     "start_time": "2023-12-02T22:47:47.111959700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
